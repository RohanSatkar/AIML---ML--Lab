{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8440d1f-ddd7-4ec8-ad1b-3db125fe3090",
   "metadata": {},
   "source": [
    "### Name - Rohan Sanjay Satkar\n",
    "### Roll No - 60\n",
    "### Pid no -  246050\n",
    "### Date - 16/02/2026\n",
    "## Expt.-5: Disease Prediction using Naive Bayes and Neural Network with Comparison of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ced3b4e-26d9-40d0-b252-f0171f914add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e71ea52-08c1-4102-aad5-2f0f79a298a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "# Load real data \n",
    "data = load_breast_cancer()\n",
    "\n",
    "X =  data.data\n",
    "y = data.target \n",
    "\n",
    "print(\"Classes:\",data.target_names)\n",
    "# malignant , benign\n",
    "\n",
    "# Split data \n",
    "X_train, X_test ,y_train, y_test = train_test_split(\n",
    "    X,y, test_size=0.3, random_state = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed2af7bc-4822-42e0-ab2e-3f7402f015c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic TestAccuracy: 0.9590643274853801\n",
      "Logistic TestAccuracy: 0.9597989949748744\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter = 5000)\n",
    "lr.fit(X_train, y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "print(\"Logistic TestAccuracy:\",accuracy_score(y_test,pred_lr))\n",
    "pred_lr_train = lr.predict(X_train)\n",
    "print(\"Logistic TestAccuracy:\",accuracy_score(y_train,pred_lr_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb2f43e3-bc55-4eb2-8901-fd425ee1b842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree TestAccuracy: 0.9005847953216374\n",
      "DecisionTree TestAccuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree \n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "pred_dt = dt.predict(X_test)\n",
    "print(\"DecisionTree TestAccuracy:\",accuracy_score(y_test,pred_dt))\n",
    "pred_dt_train = dt.predict(X_train)\n",
    "print(\"DecisionTree TestAccuracy:\",accuracy_score(y_train,pred_dt_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5324d94b-1295-4a54-b6e9-10c7d0da070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN TestAccuracy: 0.9473684210526315\n",
      "KNN TestAccuracy: 0.9396984924623115\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "pred_knn = knn.predict(X_test)\n",
    "print(\"KNN TestAccuracy:\",accuracy_score(y_test,pred_knn))\n",
    "pred_knn_train = knn.predict(X_train)\n",
    "print(\"KNN TestAccuracy:\",accuracy_score(y_train,pred_knn_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f324e53e-85f3-4e45-ad57-491bfc8239e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB TestAccuracy: 0.9239766081871345\n",
      "NB TestAccuracy: 0.9422110552763819\n"
     ]
    }
   ],
   "source": [
    "# NB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "pred_nb = nb.predict(X_test)\n",
    "print(\"NB TestAccuracy:\",accuracy_score(y_test,pred_nb))\n",
    "pred_nb_train = nb.predict(X_train)\n",
    "print(\"NB TestAccuracy:\",accuracy_score(y_train,pred_nb_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7083221-6c06-4c67-b1cb-e343e236ff57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN TestAccuracy: 0.9649122807017544\n",
      "NN TestAccuracy: 0.9371859296482412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# NN\n",
    "nn =  MLPClassifier()\n",
    "nn.fit(X_train, y_train)\n",
    "pred_nn = nn.predict(X_test)\n",
    "print(\"NN TestAccuracy:\",accuracy_score(y_test,pred_nn))\n",
    "pred_nn_train = nn.predict(X_train)\n",
    "print(\"NN TestAccuracy:\",accuracy_score(y_train,pred_nn_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a8efeb-ff1e-4ea6-aa93-0161b6589432",
   "metadata": {},
   "source": [
    "## Part 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4047e5c0-a45a-4f3f-835b-372c5bb772ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[ 62   1]\n",
      " [  6 102]]\n",
      "FP (Type-I): 1\n",
      "FN (Type-II): 6\n",
      "Type-I Error Rate in %: 1.5873015873015872\n",
      "Type-II Error Rate in %: 5.555555555555555\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "# Example confusion matrix, Type-I and Type-II error\n",
    "cm_lr = confusion_matrix(y_test, pred_lr)\n",
    "\n",
    "print(\"\\nLogistic Regression Confusion Matrix:\")\n",
    "print(cm_lr)\n",
    "\n",
    "TN2, FP2, FN2, TP2 = cm_lr.ravel()\n",
    "\n",
    "type1_lr = FP2 / (FP2 + TN2)   # False Positive Rate\n",
    "type2_lr = FN2 / (FN2 + TP2)   # False Negative Rate\n",
    "\n",
    "print(\"FP (Type-I):\", FP2)\n",
    "print(\"FN (Type-II):\", FN2)\n",
    "print(\"Type-I Error Rate in %:\", type1_lr * 100)\n",
    "print(\"Type-II Error Rate in %:\", type2_lr * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d47d592-561a-4b7b-99a1-99078559e946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RESULTS =====\n",
      "Precision         : 0.9902912621359223\n",
      "Recall            : 0.9444444444444444\n",
      "F1-score          : 0.966824644549763\n",
      "ROC-AUC           : 0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 8. Other metrics (test set)\n",
    "precision = precision_score(y_test, pred_lr)\n",
    "recall = recall_score(y_test,pred_lr)\n",
    "f1 = f1_score(y_test, pred_lr)\n",
    "roc = roc_auc_score(y_test, pred_lr)\n",
    "\n",
    "# 9. Print results\n",
    "print(\"\\n===== RESULTS =====\")\n",
    "print(\"Precision         :\", precision)\n",
    "print(\"Recall            :\", recall)\n",
    "print(\"F1-score          :\", f1)\n",
    "print(\"ROC-AUC           :\", roc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4d263f6-e98a-43f2-8e37-6715e2eaf5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Confusion Matrix:\n",
      "[[60  3]\n",
      " [14 94]]\n",
      "FP (Type-I): 3\n",
      "FN (Type-II): 14\n",
      "Type-I Error Rate in %: 4.761904761904762\n",
      "Type-II Error Rate in %: 12.962962962962962\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "# Example confusion matrix, Type-I and Type-II error\n",
    "cm_dt = confusion_matrix(y_test, pred_dt)\n",
    "\n",
    "print(\"\\nDecision Tree Confusion Matrix:\")\n",
    "print(cm_dt)\n",
    "\n",
    "TN2, FP2, FN2, TP2 = cm_dt.ravel()\n",
    "\n",
    "type1_dt = FP2 / (FP2 + TN2)   # False Positive Rate\n",
    "type2_dt = FN2 / (FN2 + TP2)   # False Negative Rate\n",
    "\n",
    "print(\"FP (Type-I):\", FP2)\n",
    "print(\"FN (Type-II):\", FN2)\n",
    "print(\"Type-I Error Rate in %:\", type1_dt * 100)\n",
    "print(\"Type-II Error Rate in %:\", type2_dt * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa4cc265-2351-4434-bf48-5602c32efc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RESULTS =====\n",
      "Precision         : 0.9690721649484536\n",
      "Recall            : 0.8703703703703703\n",
      "F1-score          : 0.9170731707317074\n",
      "ROC-AUC           : 0.9113756613756613\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 8. Other metrics (test set)\n",
    "precision = precision_score(y_test, pred_dt)\n",
    "recall = recall_score(y_test,pred_dt)\n",
    "f1 = f1_score(y_test, pred_dt)\n",
    "roc = roc_auc_score(y_test, pred_dt)\n",
    "\n",
    "# 9. Print results\n",
    "print(\"\\n===== RESULTS =====\")\n",
    "print(\"Precision         :\", precision)\n",
    "print(\"Recall            :\", recall)\n",
    "print(\"F1-score          :\", f1)\n",
    "print(\"ROC-AUC           :\", roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8329b0f-0c9d-4d73-9868-103257b87242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN Confusion Matrix:\n",
      "[[ 59   4]\n",
      " [  5 103]]\n",
      "FP (Type-I): 4\n",
      "FN (Type-II): 5\n",
      "Type-I Error Rate in %: 6.349206349206349\n",
      "Type-II Error Rate in %: 4.62962962962963\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# Example confusion matrix, Type-I and Type-II error\n",
    "cm_knn = confusion_matrix(y_test, pred_knn)\n",
    "\n",
    "print(\"\\nKNN Confusion Matrix:\")\n",
    "print(cm_knn)\n",
    "\n",
    "TN2, FP2, FN2, TP2 = cm_knn.ravel()\n",
    "\n",
    "type1_knn = FP2 / (FP2 + TN2)   # False Positive Rate\n",
    "type2_knn = FN2 / (FN2 + TP2)   # False Negative Rate\n",
    "\n",
    "print(\"FP (Type-I):\", FP2)\n",
    "print(\"FN (Type-II):\", FN2)\n",
    "print(\"Type-I Error Rate in %:\", type1_knn * 100)\n",
    "print(\"Type-II Error Rate in %:\", type2_knn * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6427899b-5f5b-4753-bede-19ce467a469b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RESULTS =====\n",
      "Precision         : 0.9626168224299065\n",
      "Recall            : 0.9537037037037037\n",
      "F1-score          : 0.958139534883721\n",
      "ROC-AUC           : 0.9451058201058201\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 8. Other metrics (test set)\n",
    "precision = precision_score(y_test, pred_knn)\n",
    "recall = recall_score(y_test,pred_knn)\n",
    "f1 = f1_score(y_test, pred_knn)\n",
    "roc = roc_auc_score(y_test, pred_knn)\n",
    "\n",
    "# 9. Print results\n",
    "print(\"\\n===== RESULTS =====\")\n",
    "print(\"Precision         :\", precision)\n",
    "print(\"Recall            :\", recall)\n",
    "print(\"F1-score          :\", f1)\n",
    "print(\"ROC-AUC           :\", roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44cdcca6-b9a6-48e6-8083-f1fe324164f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GaussianNB Confusion Matrix:\n",
      "[[ 57   6]\n",
      " [  7 101]]\n",
      "FP (Type-I): 6\n",
      "FN (Type-II): 7\n",
      "Type-I Error Rate in %: 9.523809523809524\n",
      "Type-II Error Rate in %: 6.481481481481481\n"
     ]
    }
   ],
   "source": [
    "# NB \n",
    "# Example confusion matrix, Type-I and Type-II error\n",
    "cm_nb = confusion_matrix(y_test, pred_nb)\n",
    "\n",
    "print(\"\\nGaussianNB Confusion Matrix:\")\n",
    "print(cm_nb)\n",
    "\n",
    "TN2, FP2, FN2, TP2 = cm_nb.ravel()\n",
    "\n",
    "type1_nb = FP2 / (FP2 + TN2)   # False Positive Rate\n",
    "type2_nb = FN2 / (FN2 + TP2)   # False Negative Rate\n",
    "\n",
    "print(\"FP (Type-I):\", FP2)\n",
    "print(\"FN (Type-II):\", FN2)\n",
    "print(\"Type-I Error Rate in %:\", type1_nb * 100)\n",
    "print(\"Type-II Error Rate in %:\", type2_nb * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d84c9ee-f140-4df2-9b04-0dd560e4d48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RESULTS =====\n",
      "Precision         : 0.9439252336448598\n",
      "Recall            : 0.9351851851851852\n",
      "F1-score          : 0.9395348837209302\n",
      "ROC-AUC           : 0.919973544973545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 8. Other metrics (test set)\n",
    "precision = precision_score(y_test, pred_nb)\n",
    "recall = recall_score(y_test,pred_nb)\n",
    "f1 = f1_score(y_test, pred_nb)\n",
    "roc = roc_auc_score(y_test, pred_nb)\n",
    "\n",
    "# 9. Print results\n",
    "print(\"\\n===== RESULTS =====\")\n",
    "print(\"Precision         :\", precision)\n",
    "print(\"Recall            :\", recall)\n",
    "print(\"F1-score          :\", f1)\n",
    "print(\"ROC-AUC           :\", roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97c1bd2e-c1aa-466f-8a67-6b26b723d9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NN Confusion Matrix:\n",
      "[[ 59   4]\n",
      " [  2 106]]\n",
      "FP (Type-I): 4\n",
      "FN (Type-II): 2\n",
      "Type-I Error Rate in %: 6.349206349206349\n",
      "Type-II Error Rate in %: 1.8518518518518516\n"
     ]
    }
   ],
   "source": [
    "# NN\n",
    "# Example confusion matrix, Type-I and Type-II error\n",
    "cm_nn = confusion_matrix(y_test, pred_nn)\n",
    "\n",
    "print(\"\\nNN Confusion Matrix:\")\n",
    "print(cm_nn)\n",
    "\n",
    "TN2, FP2, FN2, TP2 = cm_nn.ravel()\n",
    "\n",
    "type1_nn = FP2 / (FP2 + TN2)   # False Positive Rate\n",
    "type2_nn = FN2 / (FN2 + TP2)   # False Negative Rate\n",
    "\n",
    "print(\"FP (Type-I):\", FP2)\n",
    "print(\"FN (Type-II):\", FN2)\n",
    "print(\"Type-I Error Rate in %:\", type1_nn * 100)\n",
    "print(\"Type-II Error Rate in %:\", type2_nn * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "038df805-a60f-44e8-9f4f-1cdf1d8956d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RESULTS =====\n",
      "Precision         : 0.9636363636363636\n",
      "Recall            : 0.9814814814814815\n",
      "F1-score          : 0.9724770642201835\n",
      "ROC-AUC           : 0.958994708994709\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 8. Other metrics (test set)\n",
    "precision = precision_score(y_test, pred_nn)\n",
    "recall = recall_score(y_test,pred_nn)\n",
    "f1 = f1_score(y_test, pred_nn)\n",
    "roc = roc_auc_score(y_test, pred_nn)\n",
    "\n",
    "# 9. Print results\n",
    "print(\"\\n===== RESULTS =====\")\n",
    "print(\"Precision         :\", precision)\n",
    "print(\"Recall            :\", recall)\n",
    "print(\"F1-score          :\", f1)\n",
    "print(\"ROC-AUC           :\", roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a4bf1-6c59-467b-abc5-f2d75b0f8e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
